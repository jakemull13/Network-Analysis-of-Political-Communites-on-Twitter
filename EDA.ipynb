{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual PreProcessing (Lower Case All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all lowercase\n",
    "def lower_df_text(df, text_columns):\n",
    "    for column in text_columns:\n",
    "        df[column] = df[column].apply(lambda x: x.lower())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud(text, figname='wordcloud', rgb=(255,255,255)):\n",
    "    font_path = \"/Library/Fonts/DIN Condensed Bold.ttf\"\n",
    "    wc = WordCloud(background_color=\"white\",max_words=25,\n",
    "                   collocations=False, font_path=font_path, scale=5, color_func=lambda *args, **kwargs: rgb)\n",
    "    wc.generate(text)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14,18))\n",
    "    plt.imshow(wc)\n",
    "    plt.savefig('data/wordclouds/{}'.format(figname), dpi=240)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Network Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionize\n",
    "\n",
    "def generate_graph(edge_filepath, node_filepath, title='gephi_graph'):\n",
    "    edges = pd.read_csv(edge_filepath, header=None)\n",
    "    nodes = pd.read_csv(node_filepath, header=None)\n",
    "    edges.columns = ['Source', 'Target']\n",
    "    nodes.columns = ['Node', 'Alias']\n",
    "    nodes = nodes.astype('str')\n",
    "    edges = edges.astype('str')\n",
    "    edge_tuples = []\n",
    "    for source, target in zip(edges['Source'], edges['Target']):\n",
    "        edge_tuples.append((source, target))\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes['Node'])\n",
    "    G.add_edges_from(edge_tuples)\n",
    "    print(nx.info(G))\n",
    "    nx.write_gexf(G, edge_filepath.append('{}'.format(title)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing Pipeline (Too Slow)\n",
    "from https://www.kaggle.com/balatmak/text-preprocessing-steps-and-universal-pipeline#Reusable-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobmullins/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.semi_supervised.label_propagation module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.semi_supervised. Anything that cannot be imported from sklearn.semi_supervised is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/jacobmullins/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelPropagation from version 0.18 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "import string\n",
    "import spacy \n",
    "import en_core_web_sm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from normalise import normalise\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 variety=\"BrE\",\n",
    "                 user_abbrevs={},\n",
    "                 n_jobs=1, custom_stop_words=[]):\n",
    "        \"\"\"\n",
    "        Text preprocessing transformer includes steps:\n",
    "            1. Text normalization\n",
    "            2. Punctuation removal\n",
    "            3. Stop words removal\n",
    "            4. Lemmatization\n",
    "        \n",
    "        variety - format of date (AmE - american type, BrE - british format) \n",
    "        user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
    "        n_jobs - parallel jobs to run\n",
    "        \"\"\"\n",
    "        self.variety = variety\n",
    "        self.user_abbrevs = user_abbrevs\n",
    "        self.n_jobs = n_jobs\n",
    "        self.custom_stop_words=custom_stop_words\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, *_):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        partitions = 1\n",
    "        cores = mp.cpu_count()\n",
    "        if self.n_jobs <= -1:\n",
    "            partitions = cores\n",
    "        elif self.n_jobs <= 0:\n",
    "            return X_copy.apply(self._preprocess_text)\n",
    "        else:\n",
    "            partitions = min(self.n_jobs, cores)\n",
    "\n",
    "        data_split = np.array_split(X_copy, partitions)\n",
    "        pool = mp.Pool(cores)\n",
    "        data = pd.concat(pool.map(self._preprocess_part, data_split))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _preprocess_part(self, part):\n",
    "        return part.apply(self._preprocess_text)\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        normalized_text = self._normalize(text)\n",
    "        doc = nlp(normalized_text)\n",
    "        removed_punct = self._remove_punct(doc)\n",
    "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
    "        return self._lemmatize(removed_stop_words)\n",
    "\n",
    "    def _normalize(self, text):\n",
    "        # some issues in normalise package\n",
    "        try:\n",
    "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
    "        except:\n",
    "            return text\n",
    "\n",
    "    def _remove_punct(self, doc):\n",
    "        return [t for t in doc if t.text not in string.punctuation]\n",
    "\n",
    "    def _remove_stop_words(self, doc):\n",
    "        return [t for t in doc if t.is_stop != True and t.text not in self.custom_stop_words  and 'https' not in t.text]\n",
    "\n",
    "    def _lemmatize(self, doc):\n",
    "        return ' '.join([t.lemma_ for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Democratic Convention Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reweet_id</th>\n",
       "      <th>retweet_screen_name</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_time_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>134687.000000</td>\n",
       "      <td>1.346870e+05</td>\n",
       "      <td>7.540000e+03</td>\n",
       "      <td>1.724400e+04</td>\n",
       "      <td>134687.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.346870e+05</td>\n",
       "      <td>1.346870e+05</td>\n",
       "      <td>134687.000000</td>\n",
       "      <td>134687.000000</td>\n",
       "      <td>1.346870e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.345653</td>\n",
       "      <td>7.582166e+17</td>\n",
       "      <td>7.576638e+17</td>\n",
       "      <td>1.624101e+16</td>\n",
       "      <td>1.681061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.216183e+04</td>\n",
       "      <td>9.140628e+03</td>\n",
       "      <td>2767.032609</td>\n",
       "      <td>133.059946</td>\n",
       "      <td>4.797842e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>93.861568</td>\n",
       "      <td>5.226539e+14</td>\n",
       "      <td>1.226524e+16</td>\n",
       "      <td>1.073660e+17</td>\n",
       "      <td>60.445901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.600100e+04</td>\n",
       "      <td>9.132616e+04</td>\n",
       "      <td>7243.250845</td>\n",
       "      <td>484.443211</td>\n",
       "      <td>9.282556e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.564538e+17</td>\n",
       "      <td>4.238422e+16</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.577726e+17</td>\n",
       "      <td>7.576961e+17</td>\n",
       "      <td>1.651195e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.686000e+03</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.261000e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.581443e+17</td>\n",
       "      <td>7.580650e+17</td>\n",
       "      <td>5.524592e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.019400e+04</td>\n",
       "      <td>1.110000e+03</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.779900e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.586317e+17</td>\n",
       "      <td>7.584846e+17</td>\n",
       "      <td>5.266899e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.172300e+04</td>\n",
       "      <td>3.352000e+03</td>\n",
       "      <td>2645.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>4.917500e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30492.000000</td>\n",
       "      <td>7.594183e+17</td>\n",
       "      <td>7.594173e+17</td>\n",
       "      <td>7.591036e+17</td>\n",
       "      <td>20768.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.053126e+06</td>\n",
       "      <td>1.372433e+07</td>\n",
       "      <td>317437.000000</td>\n",
       "      <td>30229.000000</td>\n",
       "      <td>2.230300e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count            id  in_reply_to_status_id  \\\n",
       "count   134687.000000  1.346870e+05           7.540000e+03   \n",
       "mean         3.345653  7.582166e+17           7.576638e+17   \n",
       "std         93.861568  5.226539e+14           1.226524e+16   \n",
       "min          0.000000  7.564538e+17           4.238422e+16   \n",
       "25%          0.000000  7.577726e+17           7.576961e+17   \n",
       "50%          0.000000  7.581443e+17           7.580650e+17   \n",
       "75%          1.000000  7.586317e+17           7.584846e+17   \n",
       "max      30492.000000  7.594183e+17           7.594173e+17   \n",
       "\n",
       "       in_reply_to_user_id  retweet_count  reweet_id  retweet_screen_name  \\\n",
       "count         1.724400e+04  134687.000000        0.0                  0.0   \n",
       "mean          1.624101e+16       1.681061        NaN                  NaN   \n",
       "std           1.073660e+17      60.445901        NaN                  NaN   \n",
       "min           1.200000e+01       0.000000        NaN                  NaN   \n",
       "25%           1.651195e+07       0.000000        NaN                  NaN   \n",
       "50%           5.524592e+07       0.000000        NaN                  NaN   \n",
       "75%           5.266899e+08       0.000000        NaN                  NaN   \n",
       "max           7.591036e+17   20768.000000        NaN                  NaN   \n",
       "\n",
       "       user_favourites_count  user_followers_count  user_friends_count  \\\n",
       "count           1.346870e+05          1.346870e+05       134687.000000   \n",
       "mean            3.216183e+04          9.140628e+03         2767.032609   \n",
       "std             6.600100e+04          9.132616e+04         7243.250845   \n",
       "min             0.000000e+00          0.000000e+00            0.000000   \n",
       "25%             2.686000e+03          3.920000e+02          520.000000   \n",
       "50%             1.019400e+04          1.110000e+03         1166.000000   \n",
       "75%             3.172300e+04          3.352000e+03         2645.000000   \n",
       "max             1.053126e+06          1.372433e+07       317437.000000   \n",
       "\n",
       "       user_listed_count  user_statuses_count  user_time_zone  \n",
       "count      134687.000000         1.346870e+05             0.0  \n",
       "mean          133.059946         4.797842e+04             NaN  \n",
       "std           484.443211         9.282556e+04             NaN  \n",
       "min             0.000000         1.000000e+00             NaN  \n",
       "25%            11.000000         6.261000e+03             NaN  \n",
       "50%            34.000000         1.779900e+04             NaN  \n",
       "75%            97.000000         4.917500e+04             NaN  \n",
       "max         30229.000000         2.230300e+06             NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['coordinates', 'created_at', 'hashtags', 'media', 'urls',\n",
       "       'favorite_count', 'id', 'in_reply_to_screen_name',\n",
       "       'in_reply_to_status_id', 'in_reply_to_user_id', 'lang', 'place',\n",
       "       'possibly_sensitive', 'retweet_count', 'reweet_id',\n",
       "       'retweet_screen_name', 'source', 'text', 'tweet_url', 'user_created_at',\n",
       "       'user_screen_name', 'user_default_profile_image', 'user_description',\n",
       "       'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
       "       'user_listed_count', 'user_location', 'user_name', 'user_screen_name.1',\n",
       "       'user_statuses_count', 'user_time_zone', 'user_urls', 'user_verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dconvention_df = pd.read_csv('large_data/dconvention-tweet-ids.csv')\n",
    "dconvention_df.describe()\n",
    "dconvention_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobmullins/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>user_description</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_screen_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000livia</th>\n",
       "      <td>Suffolk, VA</td>\n",
       "      <td>Jesus Lover|Wife of @qfranklin23 | Mother | He...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01RedZ28</th>\n",
       "      <td>Park Ridge, NJ</td>\n",
       "      <td>New York Giants, New York Rangers, New York Ya...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>033sdn</th>\n",
       "      <td>Boardman, OH</td>\n",
       "      <td>it was the age of wisdom, it was the age of fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08meghana</th>\n",
       "      <td>Palatine, IL</td>\n",
       "      <td>Mumbaite living in USA🌎</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0SamanthaRae0</th>\n",
       "      <td>Port St John, FL</td>\n",
       "      <td>Im a mother, a sister and a daughter!♡</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwoebe</th>\n",
       "      <td>Groningen, Nederland</td>\n",
       "      <td>Drinkt Krombacher met koerspetje op z'n kop. D...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zx10arlo</th>\n",
       "      <td>Omaha, NE</td>\n",
       "      <td>Founder of Mav Motors at UNO.  Car and Bike En...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxcvanessa</th>\n",
       "      <td>Oakley, CA</td>\n",
       "      <td>always forward, never back</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyo5</th>\n",
       "      <td>Hoboken, NJ</td>\n",
       "      <td>tweetin' machine.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zytiezuhyr</th>\n",
       "      <td>Sabak, Selangor</td>\n",
       "      <td>peace ☮️</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42975 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 place  \\\n",
       "user_screen_name                         \n",
       "0000livia                  Suffolk, VA   \n",
       "01RedZ28                Park Ridge, NJ   \n",
       "033sdn                    Boardman, OH   \n",
       "08meghana                 Palatine, IL   \n",
       "0SamanthaRae0         Port St John, FL   \n",
       "...                                ...   \n",
       "zwoebe            Groningen, Nederland   \n",
       "zx10arlo                     Omaha, NE   \n",
       "zxcvanessa                  Oakley, CA   \n",
       "zyo5                       Hoboken, NJ   \n",
       "zytiezuhyr             Sabak, Selangor   \n",
       "\n",
       "                                                   user_description  \\\n",
       "user_screen_name                                                      \n",
       "0000livia         Jesus Lover|Wife of @qfranklin23 | Mother | He...   \n",
       "01RedZ28          New York Giants, New York Rangers, New York Ya...   \n",
       "033sdn            it was the age of wisdom, it was the age of fo...   \n",
       "08meghana                                   Mumbaite living in USA🌎   \n",
       "0SamanthaRae0                Im a mother, a sister and a daughter!♡   \n",
       "...                                                             ...   \n",
       "zwoebe            Drinkt Krombacher met koerspetje op z'n kop. D...   \n",
       "zx10arlo          Founder of Mav Motors at UNO.  Car and Bike En...   \n",
       "zxcvanessa                               always forward, never back   \n",
       "zyo5                                              tweetin' machine.   \n",
       "zytiezuhyr                                                 peace ☮️   \n",
       "\n",
       "                  favorite_count  retweet_count  user_followers_count  \n",
       "user_screen_name                                                       \n",
       "0000livia                      1              0                   546  \n",
       "01RedZ28                       0              0                   114  \n",
       "033sdn                         0              0                  1582  \n",
       "08meghana                      6              1                  4030  \n",
       "0SamanthaRae0                  1              0                    65  \n",
       "...                          ...            ...                   ...  \n",
       "zwoebe                         1              0                   711  \n",
       "zx10arlo                       3              0                   265  \n",
       "zxcvanessa                     0              0                   394  \n",
       "zyo5                           0              0                   236  \n",
       "zytiezuhyr                     0              0                   423  \n",
       "\n",
       "[42975 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a node df with summary columns for each user\n",
    "dnode_features = [\n",
    "       'favorite_count', 'place',\n",
    "       'retweet_count',\n",
    "       'text', \n",
    "       'user_screen_name', 'user_description',\n",
    "       'user_followers_count',\n",
    "       'user_location'\n",
    "       ]\n",
    "dnode_df = dconvention_df[dnode_features].copy()\n",
    "#fill in 'place' column if isNaN, using the location of the User.\n",
    "nan_map = dnode_df['place'].isna()\n",
    "dnode_df['place'][nan_map] = dnode_df['user_location'][nan_map]\n",
    "#group by user_id and sum various metrics for the user\n",
    "dnode_df = dnode_df.groupby(['user_screen_name', 'place', 'user_description']).sum()\n",
    "dnode_df = dnode_df.reset_index().set_index('user_screen_name')\n",
    "dnode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weeklystandard</th>\n",
       "      <td>17546958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realDonaldTrump</th>\n",
       "      <td>25073877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HillaryClinton</th>\n",
       "      <td>1339835893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natire2u</th>\n",
       "      <td>255645890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnitaDWhitee</th>\n",
       "      <td>909448512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatinoCommFdn</th>\n",
       "      <td>224810490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cspanMatthew</th>\n",
       "      <td>576520016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShellsBells143</th>\n",
       "      <td>616692598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevJacquiLewis</th>\n",
       "      <td>587591389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevKHenderson</th>\n",
       "      <td>1289348384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15737 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Id\n",
       "Label                      \n",
       "weeklystandard     17546958\n",
       "realDonaldTrump    25073877\n",
       "HillaryClinton   1339835893\n",
       "Natire2u          255645890\n",
       "AnitaDWhitee      909448512\n",
       "...                     ...\n",
       "LatinoCommFdn     224810490\n",
       "cspanMatthew      576520016\n",
       "ShellsBells143    616692598\n",
       "RevJacquiLewis    587591389\n",
       "RevKHenderson    1289348384\n",
       "\n",
       "[15737 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>place</th>\n",
       "      <th>user_description</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01elibo</th>\n",
       "      <td>2275927727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09072021</th>\n",
       "      <td>388150165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0Sundance</th>\n",
       "      <td>425116151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18899974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100DaysOfHRC</th>\n",
       "      <td>758675398913765376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zstollar</th>\n",
       "      <td>620473700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ztsamudzi</th>\n",
       "      <td>2968635633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuma02</th>\n",
       "      <td>221642866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxnaida</th>\n",
       "      <td>1070209219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzanthropology</th>\n",
       "      <td>722547659215515649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16442 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id place user_description  favorite_count  \\\n",
       "01elibo                  2275927727   NaN              NaN             NaN   \n",
       "09072021                  388150165   NaN              NaN             NaN   \n",
       "0Sundance                 425116151   NaN              NaN             NaN   \n",
       "1                          18899974   NaN              NaN             NaN   \n",
       "100DaysOfHRC     758675398913765376   NaN              NaN             NaN   \n",
       "...                             ...   ...              ...             ...   \n",
       "zstollar                  620473700   NaN              NaN             NaN   \n",
       "ztsamudzi                2968635633   NaN              NaN             NaN   \n",
       "zuma02                    221642866   NaN              NaN             NaN   \n",
       "zxnaida                  1070209219   NaN              NaN             NaN   \n",
       "zzzanthropology  722547659215515649   NaN              NaN             NaN   \n",
       "\n",
       "                 retweet_count  user_followers_count  \n",
       "01elibo                    NaN                   NaN  \n",
       "09072021                   NaN                   NaN  \n",
       "0Sundance                  NaN                   NaN  \n",
       "1                          NaN                   NaN  \n",
       "100DaysOfHRC               NaN                   NaN  \n",
       "...                        ...                   ...  \n",
       "zstollar                   NaN                   NaN  \n",
       "ztsamudzi                  NaN                   NaN  \n",
       "zuma02                     NaN                   NaN  \n",
       "zxnaida                    NaN                   NaN  \n",
       "zzzanthropology            NaN                   NaN  \n",
       "\n",
       "[16442 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.nunique of                          Id\n",
       "Label                      \n",
       "weeklystandard     17546958\n",
       "realDonaldTrump    25073877\n",
       "HillaryClinton   1339835893\n",
       "Natire2u          255645890\n",
       "AnitaDWhitee      909448512\n",
       "...                     ...\n",
       "LatinoCommFdn     224810490\n",
       "cspanMatthew      576520016\n",
       "ShellsBells143    616692598\n",
       "RevJacquiLewis    587591389\n",
       "RevKHenderson    1289348384\n",
       "\n",
       "[15737 rows x 1 columns]>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join the node data onto the mention nodes csv\n",
    "dmentions = pd.read_csv('data/democrat/convention_mentions/dmention-nodes.csv', index_col='Label')\n",
    "dmentions\n",
    "dmentions.merge(dnode_df, left_index=True, right_index=True, how='left')\n",
    "dmentions.nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Republican Convention Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reweet_id</th>\n",
       "      <th>retweet_screen_name</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_time_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>113631.000000</td>\n",
       "      <td>1.136310e+05</td>\n",
       "      <td>5.650000e+03</td>\n",
       "      <td>1.241000e+04</td>\n",
       "      <td>113631.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.136310e+05</td>\n",
       "      <td>1.136310e+05</td>\n",
       "      <td>113631.000000</td>\n",
       "      <td>113631.000000</td>\n",
       "      <td>1.136310e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.855304</td>\n",
       "      <td>7.556725e+17</td>\n",
       "      <td>7.549740e+17</td>\n",
       "      <td>1.055017e+16</td>\n",
       "      <td>1.846283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.264499e+04</td>\n",
       "      <td>1.316484e+04</td>\n",
       "      <td>2666.006187</td>\n",
       "      <td>150.543109</td>\n",
       "      <td>4.795156e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>117.449660</td>\n",
       "      <td>4.707778e+14</td>\n",
       "      <td>1.442378e+16</td>\n",
       "      <td>8.699262e+16</td>\n",
       "      <td>52.296739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.640411e+04</td>\n",
       "      <td>4.817132e+05</td>\n",
       "      <td>7370.316474</td>\n",
       "      <td>901.512807</td>\n",
       "      <td>8.528117e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.539204e+17</td>\n",
       "      <td>2.325725e+17</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.552497e+17</td>\n",
       "      <td>7.552227e+17</td>\n",
       "      <td>1.891643e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.916500e+03</td>\n",
       "      <td>3.950000e+02</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.076000e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.555901e+17</td>\n",
       "      <td>7.555728e+17</td>\n",
       "      <td>4.006901e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.036500e+04</td>\n",
       "      <td>1.162000e+03</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.965900e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.560576e+17</td>\n",
       "      <td>7.559575e+17</td>\n",
       "      <td>2.541900e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.264450e+04</td>\n",
       "      <td>3.377000e+03</td>\n",
       "      <td>2717.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>5.337700e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26220.000000</td>\n",
       "      <td>7.564522e+17</td>\n",
       "      <td>7.564517e+17</td>\n",
       "      <td>7.562792e+17</td>\n",
       "      <td>11502.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.053127e+06</td>\n",
       "      <td>7.967907e+07</td>\n",
       "      <td>508859.000000</td>\n",
       "      <td>116472.000000</td>\n",
       "      <td>1.611752e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count            id  in_reply_to_status_id  \\\n",
       "count   113631.000000  1.136310e+05           5.650000e+03   \n",
       "mean         3.855304  7.556725e+17           7.549740e+17   \n",
       "std        117.449660  4.707778e+14           1.442378e+16   \n",
       "min          0.000000  7.539204e+17           2.325725e+17   \n",
       "25%          0.000000  7.552497e+17           7.552227e+17   \n",
       "50%          0.000000  7.555901e+17           7.555728e+17   \n",
       "75%          1.000000  7.560576e+17           7.559575e+17   \n",
       "max      26220.000000  7.564522e+17           7.564517e+17   \n",
       "\n",
       "       in_reply_to_user_id  retweet_count  reweet_id  retweet_screen_name  \\\n",
       "count         1.241000e+04  113631.000000        0.0                  0.0   \n",
       "mean          1.055017e+16       1.846283        NaN                  NaN   \n",
       "std           8.699262e+16      52.296739        NaN                  NaN   \n",
       "min           1.200000e+01       0.000000        NaN                  NaN   \n",
       "25%           1.891643e+07       0.000000        NaN                  NaN   \n",
       "50%           4.006901e+07       0.000000        NaN                  NaN   \n",
       "75%           2.541900e+08       0.000000        NaN                  NaN   \n",
       "max           7.562792e+17   11502.000000        NaN                  NaN   \n",
       "\n",
       "       user_favourites_count  user_followers_count  user_friends_count  \\\n",
       "count           1.136310e+05          1.136310e+05       113631.000000   \n",
       "mean            3.264499e+04          1.316484e+04         2666.006187   \n",
       "std             6.640411e+04          4.817132e+05         7370.316474   \n",
       "min             0.000000e+00          0.000000e+00            0.000000   \n",
       "25%             2.916500e+03          3.950000e+02          545.000000   \n",
       "50%             1.036500e+04          1.162000e+03         1188.000000   \n",
       "75%             3.264450e+04          3.377000e+03         2717.000000   \n",
       "max             1.053127e+06          7.967907e+07       508859.000000   \n",
       "\n",
       "       user_listed_count  user_statuses_count  user_time_zone  \n",
       "count      113631.000000         1.136310e+05             0.0  \n",
       "mean          150.543109         4.795156e+04             NaN  \n",
       "std           901.512807         8.528117e+04             NaN  \n",
       "min             0.000000         2.000000e+00             NaN  \n",
       "25%            11.000000         7.076000e+03             NaN  \n",
       "50%            35.000000         1.965900e+04             NaN  \n",
       "75%           104.000000         5.337700e+04             NaN  \n",
       "max        116472.000000         1.611752e+06             NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['coordinates', 'created_at', 'hashtags', 'media', 'urls',\n",
       "       'favorite_count', 'id', 'in_reply_to_screen_name',\n",
       "       'in_reply_to_status_id', 'in_reply_to_user_id', 'lang', 'place',\n",
       "       'possibly_sensitive', 'retweet_count', 'reweet_id',\n",
       "       'retweet_screen_name', 'source', 'text', 'tweet_url', 'user_created_at',\n",
       "       'user_screen_name', 'user_default_profile_image', 'user_description',\n",
       "       'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
       "       'user_listed_count', 'user_location', 'user_name', 'user_screen_name.1',\n",
       "       'user_statuses_count', 'user_time_zone', 'user_urls', 'user_verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rconvention_df = pd.read_csv('large_data/rconvention-tweet-ids.csv')\n",
    "rconvention_df.describe()\n",
    "rconvention_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Democratic Candidates Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dcandidates_df = pd.read_csv('data/democrat/dcandidate-tweet-ids.csv')\n",
    "#lowercase\n",
    "lower_df_text(dcandidates_df, ['text'])\n",
    "#text process\n",
    "dcandidate_text = TextPreprocessor(n_jobs=-1, custom_stop_words=['de', 'hashtag', 'year', 'today', 'co']  ).fit_transform(dcandidates_df.text)\n",
    "#replace text column with processed text\n",
    "dcandidates_df['text'] = dcandidate_text\n",
    "#re-add the mentions and hashtags text\n",
    "dcandidates_df['hashtags'].fillna(value='', inplace=True)\n",
    "dcandidates_df['in_reply_to_screen_name'].fillna(value='', inplace=True)\n",
    "dcandidates_df['text'] = dcandidates_df['text'] + dcandidates_df['hashtags'] + dcandidates_df['in_reply_to_screen_name']\n",
    "#wordcloud\n",
    "plot_wordcloud(' '.join(rcandidate_text), figname='democratic_candidates', rgb=(0,0,255))\n",
    "#save output\n",
    "dcandidates_df.to_csv('/Users/jacobmullins/data-science-immersive/capstone_2/data/democrat/dcandidates_df.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#save text output only (for AWS)\n",
    "dcandidates_df['text'].to_csv('/Users/jacobmullins/data-science-immersive/capstone_2/data/democrat/dcandidates_text.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Republican Candidates Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rcandidates_df = pd.read_csv('data/republican/rcandidate-tweet-ids.csv')\n",
    "#lowercase\n",
    "lower_df_text(rcandidates_df, ['text'])\n",
    "#text process\n",
    "rcandidate_text = TextPreprocessor(n_jobs=-1, custom_stop_words=['de', 'hashtag', 'year', 'today', 'co', 'bit', 'ly', 'twitpic', 'bit.ly']  ).fit_transform(rcandidates_df.text)\n",
    "#replace text column with processed text\n",
    "rcandidates_df['text'] = rcandidate_text\n",
    "#re-add the mentions and hashtags text\n",
    "rcandidates_df['hashtags'].fillna(value='', inplace=True)\n",
    "rcandidates_df['in_reply_to_screen_name'].fillna(value='', inplace=True)\n",
    "rcandidates_df['text'] = rcandidates_df['text'] + rcandidates_df['hashtags'] + rcandidates_df['in_reply_to_screen_name']\n",
    "#wordcloud\n",
    "plot_wordcloud(' '.join(rcandidate_text), figname='republican_candidates', rgb=(255,0,0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#save output\n",
    "rcandidates_df.to_csv('/Users/jacobmullins/data-science-immersive/capstone_2/data/republican/rcandidates_df.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#save text output only (for AWS)\n",
    "rcandidates_df['text'].to_csv('/Users/jacobmullins/data-science-immersive/capstone_2/data/republican/rcandidates_text.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preprocessing and it’s always better to be sure that our data is cleaned %.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "p.clean('preprocessing and it’s always better to be sure that our data is cleaned 100%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
